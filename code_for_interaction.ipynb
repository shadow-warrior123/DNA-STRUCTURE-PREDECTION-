{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "i-tCtysvuJNq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.spatial.distance import cdist\n",
        "import os\n",
        "from itertools import combinations\n",
        "import logging\n",
        "import networkx as nx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6NdjvPTuvBG",
        "outputId": "607654b2-b34d-4d51-edaa-dc33b3f645d5"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CUTOFF_DISTANCE = 6.5  # Ångström\n",
        "normalization_values = {\n",
        "    'DA': 422.25,  # Adenine\n",
        "    'DT': 347.54,  # Thymine\n",
        "    'DC': 352.78,  # Cytosine\n",
        "    'DG': 492.65   # Guanine\n",
        "}"
      ],
      "metadata": {
        "id": "DxXrp7i0_sOP"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_file(file_path):\n",
        "  try:\n",
        "    data = pd.read_csv(file_path)\n",
        "    return data\n",
        "  except FileNotFoundError:\n",
        "    print(f\"File not found: {file_path}\")\n",
        "    return None\n",
        "  required_columns =  ['Atom Number', 'Residue Sequence Number', 'Residue Name', 'Chain ID', 'X', 'Y', 'Z']\n",
        "  missing_columns = [col for col in required_columns if col not in data.columns]\n",
        "  if missing_columns:\n",
        "    print(f\"Missing required columns: {', '.join(missing_columns)}\")\n",
        "  return data"
      ],
      "metadata": {
        "id": "FPNke0oFyHlV"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(data):\n",
        "  filtered_data =  data[['Atom Number', 'Residue Sequence Number', 'Residue Name', 'Chain ID', 'X', 'Y', 'Z']].copy()\n",
        "  residue_names = set(filtered_data['Residue Name'])\n",
        "  normalised_data = set(normalization_values.keys())\n",
        "  if not residue_names.issubset(normalised_data):\n",
        "    print(f\"Residue names not found in normalization values: {residue_names - normalised_data}\")\n",
        "  residue_to_nucleotide = filtered_data[['Residue Sequence Number', 'Residue Name', 'Chain ID']].drop_duplicates()\n",
        "  residue_to_nucleotide = residue_to_nucleotide.set_index('Residue Sequence Number').to_dict(orient='index')\n",
        "\n",
        "  return filtered_data, residue_to_nucleotide\n",
        ""
      ],
      "metadata": {
        "id": "yt-RAkUm7x61"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_residue_atom_mapping(filtered_data):\n",
        "    residue_atoms = filtered_data.groupby('Residue Sequence Number').apply(lambda x: x.index.tolist()).to_dict()\n",
        "    return residue_atoms"
      ],
      "metadata": {
        "id": "pc0EV-9y9s94"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_interaction_strength(residue_i, residue_j, num_contacts, residue_to_nucleotide):\n",
        "    nucleotide_i = residue_to_nucleotide.get(residue_i, {}).get('Residue Name')\n",
        "    nucleotide_j = residue_to_nucleotide.get(residue_j, {}).get('Residue Name')\n",
        "    N_i = normalization_values.get(nucleotide_i, 1)\n",
        "    N_j = normalization_values.get(nucleotide_j, 1)\n",
        "    if num_contacts > 0:\n",
        "        return (num_contacts * 100) / np.sqrt(N_i * N_j)\n",
        "    return 0"
      ],
      "metadata": {
        "id": "oxfkzGR19xjP"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def construct_dsg(filtered_data, residue_to_nucleotide):\n",
        "    logging.info(\"Constructing DNA Structure Graph (DSG)...\")\n",
        "    residue_atoms = build_residue_atom_mapping(filtered_data)\n",
        "    G = nx.Graph()\n",
        "    interaction_details = []\n",
        "    residues = list(residue_to_nucleotide.keys())\n",
        "    total_pairs = len(residues) * (len(residues) - 1) // 2\n",
        "    logging.info(f\"Total unique residues: {len(residues)}\")\n",
        "    logging.info(f\"Total residue pairs to process: {total_pairs}\")\n",
        "    for idx, (residue_i, residue_j) in enumerate(combinations(residues, 2), 1):\n",
        "        if idx % 1000 == 0 or idx == 1:\n",
        "            logging.info(f\"Processing residue pair {idx}/{total_pairs}...\")\n",
        "\n",
        "        if residue_i == residue_j:\n",
        "            continue\n",
        "\n",
        "        chain_i = residue_to_nucleotide.get(residue_i, {}).get('Chain ID')\n",
        "        chain_j = residue_to_nucleotide.get(residue_j, {}).get('Chain ID')\n",
        "        same_chain = chain_i == chain_j\n",
        "\n",
        "        if same_chain:\n",
        "            residue_i_seq = residue_i\n",
        "            residue_j_seq = residue_j\n",
        "            if abs(residue_i_seq - residue_j_seq) < 2:\n",
        "                continue\n",
        "\n",
        "        atoms_i = residue_atoms.get(residue_i, [])\n",
        "        atoms_j = residue_atoms.get(residue_j, [])\n",
        "\n",
        "        if not atoms_i or not atoms_j:\n",
        "            continue\n",
        "\n",
        "        coords_i = filtered_data.loc[atoms_i, ['X', 'Y', 'Z']].values\n",
        "        coords_j = filtered_data.loc[atoms_j, ['X', 'Y', 'Z']].values\n",
        "        distances = cdist(coords_i, coords_j)\n",
        "        num_contacts = np.sum(distances < CUTOFF_DISTANCE)\n",
        "\n",
        "        if num_contacts == 0:\n",
        "            continue\n",
        "\n",
        "        interaction_strength = calculate_interaction_strength(residue_i, residue_j, num_contacts, residue_to_nucleotide)\n",
        "\n",
        "        if interaction_strength > 0:\n",
        "            G.add_node(residue_i)\n",
        "            G.add_node(residue_j)\n",
        "            G.add_edge(residue_i, residue_j, weight=interaction_strength)\n",
        "\n",
        "            interaction_details.append([\n",
        "                residue_i,\n",
        "                residue_j,\n",
        "                residue_to_nucleotide.get(residue_i, {}).get('Residue Name'),\n",
        "                residue_to_nucleotide.get(residue_j, {}).get('Residue Name'),\n",
        "                num_contacts,\n",
        "                interaction_strength\n",
        "            ])\n",
        "\n",
        "\n",
        "    return G, interaction_details"
      ],
      "metadata": {
        "id": "UHJtAn35-KT_"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_interaction_details(interaction_details, output_file_path):\n",
        "    if not interaction_details:\n",
        "        logging.warning(\"No interaction details to save.\")\n",
        "        return\n",
        "\n",
        "    interaction_df = pd.DataFrame(\n",
        "        interaction_details,\n",
        "        columns=[\n",
        "            'Residue_Number_1',\n",
        "            'Residue_Number_2',\n",
        "            'Nucleotide_1',\n",
        "            'Nucleotide_2',\n",
        "            'Atomic_Pair_Count',\n",
        "            'Interaction_Strength'\n",
        "        ]\n",
        "    )\n",
        "    try:\n",
        "        interaction_df.to_csv(output_file_path, index=False)\n",
        "        logging.info(f\"Interaction details saved to {output_file_path}.\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Failed to save interaction details to {output_file_path}: {e}\")\n",
        "        raise"
      ],
      "metadata": {
        "id": "dNjlridg-Zc8"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_file(input_file_path, output_file_path):\n",
        "    logging.info(f\"Starting processing for file: {input_file_path}\")\n",
        "    data = load_file(input_file_path)\n",
        "    filtered_data, residue_to_nucleotide = preprocess_data(data)\n",
        "    G, interaction_details = construct_dsg(filtered_data, residue_to_nucleotide)\n",
        "    save_interaction_details(interaction_details, output_file_path)\n",
        "    logging.info(f\"Completed processing for file: {input_file_path}\")\n"
      ],
      "metadata": {
        "id": "UhD7eLlU-hFg"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_FOLDER = '/content/drive/MyDrive/weekend_project/csv_folder/B-DNA '\n",
        "OUTPUT_FOLDER = '/content/drive/MyDrive/weekend_project/Interaction_Folder/B_DNA '"
      ],
      "metadata": {
        "id": "OIdKeu2CAE03"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def process_csv_files(input_folder, output_folder):\n",
        "\n",
        "  if not os.path.exists(output_folder):\n",
        "      os.makedirs(output_folder)\n",
        "\n",
        "  for filename in os.listdir(input_folder):\n",
        "    if filename.endswith(\".csv\"):\n",
        "      input_file_path = os.path.join(input_folder, filename)\n",
        "      output_file_path = os.path.join(output_folder, f\"interaction_{filename}\")\n",
        "      process_file(input_file_path, output_file_path)\n",
        "\n",
        "# Example usage:\n",
        "process_csv_files(INPUT_FOLDER, OUTPUT_FOLDER)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOuKbND-F3db",
        "outputId": "f67967e4-056f-489d-8aa7-d677ace594b4"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-b4a58f5f43fc>:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  residue_atoms = filtered_data.groupby('Residue Sequence Number').apply(lambda x: x.index.tolist()).to_dict()\n",
            "<ipython-input-31-b4a58f5f43fc>:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  residue_atoms = filtered_data.groupby('Residue Sequence Number').apply(lambda x: x.index.tolist()).to_dict()\n",
            "<ipython-input-31-b4a58f5f43fc>:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  residue_atoms = filtered_data.groupby('Residue Sequence Number').apply(lambda x: x.index.tolist()).to_dict()\n",
            "<ipython-input-31-b4a58f5f43fc>:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  residue_atoms = filtered_data.groupby('Residue Sequence Number').apply(lambda x: x.index.tolist()).to_dict()\n",
            "<ipython-input-31-b4a58f5f43fc>:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  residue_atoms = filtered_data.groupby('Residue Sequence Number').apply(lambda x: x.index.tolist()).to_dict()\n",
            "<ipython-input-31-b4a58f5f43fc>:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  residue_atoms = filtered_data.groupby('Residue Sequence Number').apply(lambda x: x.index.tolist()).to_dict()\n",
            "<ipython-input-31-b4a58f5f43fc>:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  residue_atoms = filtered_data.groupby('Residue Sequence Number').apply(lambda x: x.index.tolist()).to_dict()\n",
            "<ipython-input-31-b4a58f5f43fc>:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  residue_atoms = filtered_data.groupby('Residue Sequence Number').apply(lambda x: x.index.tolist()).to_dict()\n",
            "<ipython-input-31-b4a58f5f43fc>:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  residue_atoms = filtered_data.groupby('Residue Sequence Number').apply(lambda x: x.index.tolist()).to_dict()\n",
            "<ipython-input-31-b4a58f5f43fc>:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  residue_atoms = filtered_data.groupby('Residue Sequence Number').apply(lambda x: x.index.tolist()).to_dict()\n"
          ]
        }
      ]
    }
  ]
}